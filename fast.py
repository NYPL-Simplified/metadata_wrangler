import gzip
import csv
import logging
import os
import re
from nose.tools import set_trace
import time
logging.getLogger().setLevel("DEBUG")
class FASTNames(dict):

    SUBDIR = "FAST"

    triple_re = re.compile('^<http://id.worldcat.org/fast/([0-9]+)> <http://schema.org[#/]name> "([^"]+)"')

    @classmethod
    def from_data_directory(cls, data_directory):
        """Load names from a directory that either contains a bunch of
        files in N-Triples format or a single consolidated CSV file.
        """
        my_directory = os.path.join(data_directory, cls.SUBDIR)
        consolidated_file = os.path.join(my_directory, "consolidated.csv.gz")
        a = time.time()
        if os.path.exists(consolidated_file):
            # A consolidated file has already been created. Load it --
            # it's quick.
            names = cls.from_consolidated_file(consolidated_file)
        else:
            # We have to go through a bunch of N-Triples files.
            names = cls()
            for i in os.listdir(my_directory):
                if not i.endswith(".nt.gz") and not i.endswith(".nt"):
                    continue
                path = os.path.join(my_directory, i)
                logging.info("Loading %s names from %s", cls.SUBDIR, path)
                names.load_triples_file(path)
                logging.info(
                    "There are now %d %s names.", len(names), cls.SUBDIR
                )

            # Now that we've done that, write out a consolidated file
            # so next time will go more quickly.
            names.write_consolidated_file(consolidated_file)
        b = time.time()
        logging.info("Done loading %s names in %.1f sec", cls.SUBDIR, (b-a))
        return names

    def load_triples_file(self, path):
        """Load classifications from an N-Triples file."""
        fh = gzip.open(path, 'rb')
        for triple in fh:
            identifier, name = self.extract_identifier_and_name(triple)
            if identifier and name:
                self[identifier] = name

    def extract_identifier_and_name(self, triple):
        """Extract an identifier and a name from
        a single line of an N-Triples file.
        """
        triple = triple.strip()
        g = self.triple_re.search(triple)
        if not g:
            return None, None
        return g.groups()

    @classmethod
    def from_consolidated_file(cls, path):
        """Load classifications from a CSV file, generated by an
        earlier call to write_consolidated_file().
        """
        logging.info(
            "Reading cached %s names from %s", cls.SUBDIR, path
        )
        names = cls()
        fh = gzip.open(path, 'rb')
        reader = csv.reader(fh)
        for k, v in reader:
            names[k] = v
        return names

    def write_consolidated_file(self, path):
        """Write a CSV file containing information consolidated
        from several N-Triples files.
        """
        output = gzip.open(path, "wb")
        writer = csv.writer(output)
        for k,v in self.items():
            writer.writerow([k, v])
        output.close()


class LCSHNames(FASTNames):

    # TODO: This doesn't work on the childrens' subject classifications;
    # we need to do something closer to real RDF work for those.

    SUBDIR = "LCSH"
    triple_re = re.compile('^<http://id.loc.gov/authorities/[a-zA-Z]+/([a-z]+[0-9]+)> <http://www.loc.gov/mads/rdf/v1#authoritativeLabel> "([^"]+)"@en')
